---
title: "Predicting and Understanding NBA Career Length"
author: "Brandon Chan + Lucas Duncan"
date: "2025-03-07"
output: html_document
---

```{r}
#NOTES TO SELF:::::::::
  
#-GPA is sum of 4 Classes, So any model cant use all 4




```

## Executive Summary and Contents
```{r}
contents <- tribble(
  ~Index, ~Category, ~Method,
  1, "Introduction", "Written",
  2, "Preprocessing", "Data Description and Encoding",
  3, "Unsupervised Learning/Analysis", "PCA and Clustering",
  4, "Preprocessing", "Variable Selection",
  5, "Supervised Regression", "Linear and Non-Linear Regression",
  6, "Supervised Classification", "LDA/QDA and Logistic Regression",
  7, "Supervised Classification", "Tree-Based Methods",
  8, "Supervised Classification", "Support Vector Machines",
  9, "Deep Learning", "Neural Networks",
  10, "Conclusion", "Written", 
)
contents
```


### 2: Preprocessing




## 2.0: Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(e1071)
library(MASS)
library(tidyverse)
library(caret)
library(leaps)
library(tidyr)
library(ggplot2)
library(glmnet)
select <- dplyr::select
```


## 2.1 Extract Data
```{r, warning=FALSE}
location = "https://raw.githubusercontent.com/BrandonYChan/Statistical-Learning/main/Student_performance_10k.csv"

(df <- read_csv(location, show_col_types = FALSE))
```

## 2.2 Clean Data
```{r}
df2 <- df |>
       rename(
         "has_subsidized_lunch" = "lunch",
         "has_prepared" = "test_preparation_course",
         "is_male" = "gender",
         "parent_education" = "parental_level_of_education",
         "gpa" = "total_score",
         "gpa_letter" = "grade"
       ) |> 
       mutate(
         is_male = as.integer(if_else(is_male =="male",1,0)),
         race_ethnicity = str_sub(df$race_ethnicity, -1, -1),
         gpa = gpa/4,
         gpa_letter = if_else(gpa_letter == "Fail", "F", gpa_letter)
       ) |>
       select(-c("roll_no","science_score","writing_score"))
```

## 2.3 Interpolate NA values
```{r}
#Remove Any Duplicates
df3 <- distinct(df2)

#Replace Missing NUMERIC Values With Column Mean
if (any(is.na(df3))) {
  df3[] <- lapply(df3, function(x) {
    if (is.numeric(x)) {
      replace(x, is.na(x), mean(x, na.rm = TRUE))
    } else {
      x
    }
  })
}

#Dropping Missing Factor Columns
df3 <- df3[complete.cases(df3[c("race_ethnicity", "parent_education", "gpa_letter")]), ]
```

## 2.4 Format For Classification + Regression
```{r}
#REGRESSION: PREDICT GPA (0-100)
# Convert Categories Into ONEHOT Notation
df_reg <- df3 |> bind_cols(as.data.frame(model.matrix(~ `race_ethnicity` + `parent_education` - 1, data = df3))) |>
                 select(-c("race_ethnicity","parent_education","gpa_letter"))

#CLASSIFICATION: PREDICT GPA_LETTER (A-F)
df_cls <- df3 |> mutate(race_ethnicity = as.factor(race_ethnicity),
                        parent_education = as.factor(parent_education),
                        gpa_letter = as.factor(gpa_letter)) |>
                 select(-c("gpa"))
```


## 2.5 Display Variable Distributions
```{r}
#Display Numeric
df_numeric <- df_cls |> select(where(is.numeric)) |> pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
ggplot(df_numeric, aes(x = value)) + geom_histogram(bins = 30) +  facet_wrap(~ variable, scales = "free")  

#Display Factor
df_factor <- df_cls |> select(where(is.factor)) |> pivot_longer(cols = everything(), names_to = "variable", values_to = "value") 
ggplot(df_factor, aes(x = value)) + geom_bar() + facet_wrap(~ variable, scales = "free") 
```
## 2.6 Split Into Train + Test Sets
```{r}

#Splits Rows
train_index <- sample(1:nrow(df_reg), nrow(df_reg)*0.8)

#Generates Training + Test Set For Classification + Regression Techniques
train_reg <- df_reg[train_index,]
test_reg <- df_reg[-train_index,]

train_cls <- df_cls[train_index,]
test_cls <- df_cls[-train_index,]
```



# 3 Data Exploration with Unsupervised Methods 


## 2.1 Principal Component Analysis
```{r}
# Find Principal Components
pr <- prcomp(df_reg, scale=TRUE)

# Show Impact of Variables on the First Principle Component
pc1 <- pr$rotation[,1]
(pc1_loading_df <- cbind(names(pc1), as_data_frame(pc1)) |>
                  rename("names" = "names(pc1)", "pc1_loading" = "value") |> 
                  arrange(desc(abs(pc1_loading))))
```


```{r}
# Show Proportion of Variance Explained (PVE)
pve <- pr$sdev^2 / sum(pr$sdev^2)   

pve_df <- as_data_frame(cbind(1:length(pve), pve)) %>% # Show PVE for each number of principal components
  mutate(cumulative_pve = cumsum(pve)) %>% # Cumulative PVE for each additional PC 
  rename("num_principal_components" = "V1")
  
pve_df
```

```{r}
# Show projections of data onto first 2 PCs
biplot(pr, scale = 0, cex=0.4)
```

## K-Means Clustering on PC1 and PC2

```{r}
km <- kmeans(pr$x, 3, nstart=50)
plot(pr$x, col = (km$cluster +1), pch=20, cex=2)
```

# Variable Selection

```{r}
par(mfrow=c(1,3))

# Best subset selection
best_subset <- regsubsets(gpa~., df_reg, nvmax = ncol(df_reg))
(bs_summary <- summary(best_subset))

# BIC plot
plot(seq_len(length(bs_summary$bic)), bs_summary$bic, type="b", xlab="Number of predictors", ylab="BIC",ylim=c(-9500,-8000))
points(which.min(bs_summary$bic), min(bs_summary$bic), col="red", cex=2, pch=20) 

# cp plot
plot(seq_len(length(bs_summary$cp)), bs_summary$cp, type="b", xlab="Number of predictors", ylab="CP",ylim=c(0,20))
points(which.min(bs_summary$cp), min(bs_summary$cp), col="red", cex=2, pch=20)
lines(seq_along(bs_summary$cp), seq_along(bs_summary$cp)+1, col="gray", lty=2)

# Adjusted R^2 plot
plot(seq_len(length(bs_summary$adjr2)), bs_summary$adjr2, type="b", xlab="Number of predictors", ylab="R^2",ylim=c(0.45,1))
points(which.max(bs_summary$adjr2), max(bs_summary$adjr2), col="red", cex=2, pch=20)
```

```{r}
tibble(Best_BIC = which.min(bs_summary$bic), Cest_Cp = which.min(bs_summary$cp), Best_Adjusted_Rsq = which.max(bs_summary$adjr2))

# What do we do with this they're all different

#BIC HEAVILY PENALIZED COMPLEXITY, BUT ADRSQ, AND CP BOTH SEEM TO BE OKAY WITH HIGHER, AND THE FACT LOTS OF THESE ARE ONE HOT VARIABLES MAKES ME THINK SLIGHTLY MORE IS OKAY, MAYBE WE JUST CHOOISE SOMETHING RANDOM FOR NOW, USE IT TO MOVE ON, THEN COME BACK

p = 8
```


#LINEAR REGRESSION

```{r}

train_x <- as.matrix(train_reg[, -c(6)])
train_y <- as.matrix(train_reg$gpa)

test_x <- as.matrix(test_reg[, -c(6)])
test_y <- as.matrix(test_reg$gpa)


#Linear Model
linear_model <- lm(gpa ~ ., data=train_reg)
linear_preds <- predict(linear_model, test_reg)
RMSE_linear = RMSE(test_y, linear_preds)
# summary(linear_model)

#LASSO:
optimal_lambda <- cv.glmnet(train_x, train_y, alpha=1)$lambda.min
lasso_model <- glmnet(train_x, train_y, alpha=1, lambda=optimal_lambda)
lasso_predictions <- predict(lasso_model, newx=test_x, s=optimal_lambda)
RMSE_lasso =  RMSE(test_y, lasso_predictions)
# coef(lasso_model)

#Ridge
optimal_lambda <- cv.glmnet(train_x, train_y, alpha=0)$lambda.min
ridge_model <- glmnet(train_x, train_y, alpha=0, lambda=optimal_lambda)
ridge_predictions <- predict(ridge_model, newx=test_x, s=optimal_lambda)
RMSE_ridge = RMSE(test_y, ridge_predictions)
# coef(ridge_model)

tribble(~"Unregularised RMSE", ~"LASSO RMSE", ~"Ridge RMSE",
        RMSE_linear, RMSE_lasso, RMSE_ridge)

# LASSO regression performs the best of these

```

#NON-LINEAR REGRESSION

```{r}
# Polynomial Regression

# Natural Splines

# Generalized Additive Model (GAM)

```


#LDA + QDA
```{r}

lda_model <- lda(gpa_letter ~ ., data = train_cls)

lda_preds <- predict(lda_model, newdata = test_cls)

lda_class <- lda_preds$class

table(lda_class, test_cls$gpa_letter)


accuracy <- mean(lda_class == test_cls$gpa_letter)
print(accuracy)
summary(lda_model)

#PERHAPS DISPLAY USING PC PLOT
```


```{r}
#QDA:

#READ:
#some groups are too small size for QDA to work (its an actual error), so as a group we gotta decide how we want to handle that

# I think we just get rid of it and group LDA with logistic regression under the same header 
```


```{r, include=FALSE}


#LOGISTIC REGRESSION

library(nnet)
 
log_reg_model <- multinom(gpa_letter ~ ., data = train_cls)
 
log_reg_pred_probs <- predict(log_reg_model, newdata = test_cls, type = "probs")
log_reg_pred_class <- predict(log_reg_model, newdata = test_cls, type = "class")
 
 
 log_reg_accuracy <- mean(log_reg_pred_class == test_cls$gpa_letter)
 
 #MIGHT WANT TO OVERLAY OVER PC GRAPH

```

```{r}
print(log_reg_accuracy)
# summary(log_reg_model)
```



```{r}
#SVM
library(e1071)


try = seq(1, 10, by = 3)

#ATTEMPTING TO DETERMINE THE RELATIONSHIP OF DATA (IE LINEAR,QUADRATIC,RADIAL)

#from PC, we expect Linear Model To Work Well

best <- tune(svm, gpa_letter ~ ., data = train_cls, ranges = list(cost = try),kernel="linear")$best.parameters$cost
linear_kernel_svm <- svm(gpa_letter ~ .,data=train_cls, cost=best, kernel="linear")
mean(predict(linear_kernel_svm, test_cls, type="class") != test_cls$gpa_letter)

best <- tune(svm, gpa_letter ~ ., data = train_cls, ranges = list(cost = try), kernel="radial")$best.parameters$cost
radial_kernel_svm <- svm(gpa_letter ~ .,data=train_cls, cost=best, kernel="radial")
mean(predict(radial_kernel_svm, test_cls, type="class") != test_cls$gpa_letter)

best <- tune(svm, gpa_letter ~ ., data = train_cls, ranges = list(cost = try), kernel="polynomial",degree=2)$best.parameters$cost
quadratic_kernel_svm <- svm(gpa_letter ~ .,data=train_cls, cost=best, kernel="polynomial",degree=2)
mean(predict(quadratic_kernel_svm, test_cls, type="class") != test_cls$gpa_letter)

```











